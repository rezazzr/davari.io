- name: Road Crossing Aid for Visually Impaired
  descr: There are over 37 million people across the globe who are visually impaired. Out of this population, over 15 million are from India. Living in an underdeveloped country with little infrastructure for the disables could be very harsh and isolating. We wanted to make a difference and not let their disabilities hinder their day to day life. This motivation drove us to develop the project presented here. In this project, we designed, made and tested and application that uses AI to navigate and guide the visually impaired in crossing the street. In our first attempt in solving this problem we are considering the case of zebra line crossings. The full report and implementation of the AI part of the project can be found in the github repository linked below. A demo of the application running on android platform could be seen in this <a href="https://www.youtube.com/watch?time_continue=2&v=fUke4D1N3ss">video</a>.
  github: https://github.com/rezazzr/Road-Crossing-Aid-For-The-Visually-Impaired

- name: Reinforcement Learning in Sports&#58 Cricket  
  descr: Reinforcement learning has already made its mark of expertise in two player strategy games such as chess and GO that require sequential decision making. The game of cricket is also a game between two high level entities (teams) and involves sequential decision making under uncertainty. It requires customizing one's strategy according to the situation they are facing. At the heart of it, we can view it with similar reinforcement learning problem formulation where the teams can be modeled as agents. In this project we are aiming to find the optimal strategy, using reinforcement learning techniques, for the 2 teams playing against each other.If you are not familiar with the game of cricket, you can read more about the game, <a href="https://en.wikipedia.org/wiki/Cricket">here</a>.
  github: https://github.com/rezazzr/AI-in-Sports-Cricket

- name: Variational Auto Encoders (VAE) 
  descr: This is a report on the development of a VAE model and experiments performed on it to better understand its functionality and properties. The first 2 sections of the report are dedicated to the development of the model and the choices that came along with it. A general overview of the architecture is presented in section 1. Section 2 tries to demonstrate the different methods that could be used to increase the feature map size. The analysis presented in this section is both from a visual aspect and mathematical one. Section 3 explores the properties of VAE for a better understanding of its functionality and presents some analysis between the vanilla VAE and <a href="https://arxiv.org/abs/1509.00519">IWAE</a>. In section 4 the model presented in the report will be evaluated in a more quantitative setting for future comparisons.
  github: https://github.com/rezazzr/variational-auto-encoders

- name: General Value Functions and Successor Representation
  descr: This is a report on the topic of Successor Representation (SR). It briefly discusses the relation between SR and the General Value Functions and then proceeds to explore the properties of SR and its benefits over vanilla TD(0) methods. The experiments performed for the purposes of this study are all done on the <a href="https://gym.openai.com/envs/FrozenLake-v0/">FrozenLake</a> environment with slight modifications that are mentioned in the report.
  github: https://github.com/rezazzr/GVF_SR_reinforcement_learning

- name: Policy Gradient Methods in Reinforcement Learning
  descr: This is a report on the use of policy gradient methods in Reinforcement Learning. The focus of this report is on the experimental comparison between 3 types of Actor-Critic methods. This investigation mainly revolves around the effect of the eligibility traces on Actor-Critic methods. These methods are the followings&#58 <ol> <li>Actor-Critic with Eligibility Traces</li> <li>Actor-Critic with Eligibility Traces only on the Critic but not the Actor</li> <li>Actor-Critic Without any Eligibility Traces using one-step returns</li>  </ol> The experiments are carried on the <a href="https://gym.openai.com/envs/FrozenLake-v0/">FrozenLake</a> environment.
  github: https://github.com/rezazzr/policy_gradient_reinforcement_learning